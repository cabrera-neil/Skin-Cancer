{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from scipy import misc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ReduceLROnPlateau \n",
    "from keras.utils import np_utils, normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = './Data/'\n",
    "PATH_IMAGES = glob.glob('./Images/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv(PATH_DATA + 'HAM10000_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta['dx_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta['localization'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation\n",
    "### Method 1 results in dead kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Load all Images and Scale by 255\n",
    "# images = []\n",
    "# for path_image in PATH_IMAGES:\n",
    "#     image = misc.imread(path_image)\n",
    "#     image = image / 255\n",
    "#     images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 can be completed with approx 3GB memory consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Load all Images and Resize to 50%, no scaling\n",
    "# images = []\n",
    "# for path_image in PATH_IMAGES:\n",
    "#     image = misc.imread(path_image)\n",
    "#     image = misc.imresize(image, size=(300, 225), interp='nearest')\n",
    "#     images.append(image)\n",
    "#     print('Completed processing {}'.format(path_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3 can be completed with approx 5GB memory consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 3: Load all Images and Resize to 70%, no scaling\n",
    "# images = []\n",
    "# for path_image in PATH_IMAGES:\n",
    "#     image = misc.imread(path_image)\n",
    "#     image = misc.imresize(image, size=(420, 315), interp='nearest')\n",
    "#     images.append(image)\n",
    "#     print('Completed processing {}'.format(path_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = np.asarray(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.asarray([images.shape[1], images.shape[2], images.shape[3]])\n",
    "# array([420, 315,   3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4 scaling values takes up entire 16GB + swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 4: Load all Images and Resize to 50%, with scaling\n",
    "# images = []\n",
    "# for path_image in PATH_IMAGES:\n",
    "#     image = misc.imread(path_image)\n",
    "#     image = misc.imresize(image, size=(300, 225), interp='nearest')\n",
    "#     image = image / 255\n",
    "#     images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is working, redo this later\n",
    "# figure = plt.figure()\n",
    "# count = 0\n",
    "# for index, row in df_combined.iterrows():\n",
    "#     if count < 10:\n",
    "#         plt.imshow(row['image'])\n",
    "#         plt.axis('off')\n",
    "#         count += 1\n",
    "#     else:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling - CNN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Train and Test Data\n",
    "df_meta = df_meta.set_index('image_id')\n",
    "y = df_meta['dx']\n",
    "y_train, y_test = train_test_split(y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Size: 600*450\n",
    "# Metho: Load all Images and Resize to 30%, with normalization\n",
    "\n",
    "TARGET_SIZE = (180, 135)\n",
    "\n",
    "x_train, x_test = [], []\n",
    "for image_id in y_train.index.values:\n",
    "    # Uses too much memory, will revert first to scipy\n",
    "    # image = imageio.imread('./Images/{}.jpg'.format(image_id))\n",
    "    # image = resize(image, output_shape=(360, 270), anti_aliasing=False, mode='constant')\n",
    "    \n",
    "    image = misc.imread('./Images/{}.jpg'.format(image_id))\n",
    "    image = misc.imresize(image, size=TARGET_SIZE, interp='nearest')\n",
    "    image = normalize(image)\n",
    "    x_train.append(image)\n",
    "    print('Completed processing {}.jpg'.format(image_id))\n",
    "\n",
    "x_train = np.asarray(x_train)\n",
    "\n",
    "for image_id in y_test.index.values:\n",
    "    # Uses too much memory, will revert first to scipy\n",
    "    # image = imageio.imread('./Images/{}.jpg'.format(image_id))\n",
    "    # image = resize(image, output_shape=(360, 270), anti_aliasing=False, mode='constant')\n",
    "    \n",
    "    image = misc.imread('./Images/{}.jpg'.format(image_id))\n",
    "    image = misc.imresize(image, size=TARGET_SIZE, interp='nearest')\n",
    "    image = normalize(image)\n",
    "    x_test.append(image)\n",
    "    print('Completed processing {}.jpg'.format(image_id))\n",
    "\n",
    "x_test = np.asarray(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = y_test.value_counts()\n",
    "\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_object_array(arr):\n",
    "    # One hot encode a numpy array of objects (e.g. strings)'''\n",
    "    uniques, ids = np.unique(arr, return_inverse=True)\n",
    "    return np_utils.to_categorical(ids, len(uniques))\n",
    "\n",
    "y_train = one_hot_encode_object_array(y_train)\n",
    "y_test = one_hot_encode_object_array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(size, n_layers):\n",
    "    # INPUTS\n",
    "    # size     - size of the input images\n",
    "    # n_layers - number of layers\n",
    "    # OUTPUTS\n",
    "    # model    - compiled CNN\n",
    "\n",
    "    # Define hyperparamters\n",
    "    MIN_NEURONS = 64\n",
    "    MAX_NEURONS = 256 # change this, make it 256, 512\n",
    "    KERNEL = (3, 3)\n",
    "\n",
    "    # Determine the # of neurons in each convolutional layer\n",
    "    neurons = np.arange(MIN_NEURONS, MAX_NEURONS, MIN_NEURONS/2)\n",
    "    neurons = neurons.astype(np.int32)\n",
    "\n",
    "    # Define a model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add convolutional layers\n",
    "    for i in range(0, n_layers):\n",
    "        if i == 0:\n",
    "            shape = (size[0], size[1], size[2])\n",
    "            model.add(Conv2D(neurons[i], KERNEL, padding='same', input_shape=shape))\n",
    "        else:\n",
    "            model.add(Conv2D(neurons[i], KERNEL, padding='same'))\n",
    "        \n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "    # Add max pooling layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.40))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(MAX_NEURONS))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.50))\n",
    "\n",
    "    # Add output layer\n",
    "    model.add(Dense(7))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Print a summary of the model\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "N_LAYERS = 4\n",
    "image_size = np.asarray([x_train.shape[1], x_train.shape[2], x_train.shape[3]])\n",
    "model = cnn(size=image_size, n_layers=N_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparamters\n",
    "EPOCHS = 64\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Add a reduction of learning rate to the model\n",
    "reduce_lr = ReduceLROnPlateau(monitor='acc', factor=0.5, patience=3, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model_history = model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction on the test set\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train, verbose=1, batch_size=BATCH_SIZE)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Previous Value Counts of y_test and compare with the classification report below\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test.argmax(axis=1), test_predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the Classification Report\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis...\n",
    "- There is a huge data imbalance which causes the rest of the data to be classified wrongly as nv\n",
    "- Will re-run this by combining all dx (not nv) as others and compare again\n",
    "- Update the CNN function by adding dropout layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "model_file = open('model-eda-preliminary-cnn5.sav','wb')\n",
    "pickle.dump(model, model_file)\n",
    "model_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
